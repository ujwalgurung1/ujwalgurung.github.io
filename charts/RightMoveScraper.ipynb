{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "RightMoveScraper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Code Adapted and inspired by Code Monkey King \n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "from google.colab import files\n",
        "\n",
        "class RightmoveScraper:\n",
        "    results = []    \n",
        "    \n",
        "    def fetch(self, url):\n",
        "        print('HTTP GET request to URL: %s' % url, end='')\n",
        "        response = requests.get(url)\n",
        "        print(' | Status code: %s' % response.status_code)\n",
        "        \n",
        "        return response\n",
        "    \n",
        "    def parse(self, html):\n",
        "        content = BeautifulSoup(html, 'lxml')\n",
        "        \n",
        "        titles = [title.text.strip() for title in content.findAll('h2', {'class': 'propertyCard-title'})]\n",
        "        addresses = [address['content'] for address in content.findAll('meta', {'itemprop': 'streetAddress'})]\n",
        "        descriptions = [description.text for description in content.findAll('span', {'data-test': 'property-description'})]\n",
        "        prices = [price.text.strip() for price in content.findAll('div', {'class': 'propertyCard-priceValue'})]\n",
        "        dates = [date.text.split(' ')[-1] for date in content.findAll('span', {'class': 'propertyCard-branchSummary-addedOrReduced'})]\n",
        "        sellers = [seller.text.split('by')[-1].strip() for seller in content.findAll('span', {'class': 'propertyCard-branchSummary-branchName'})]\n",
        "        images = [image['src'] for image in content.findAll('img', {'itemprop': 'image'})]\n",
        "        \n",
        "        for index in range(0, len(titles)):\n",
        "            self.results.append({\n",
        "                'title': titles[index],\n",
        "                'address': addresses[index],\n",
        "                'description': descriptions[index],\n",
        "                'price': prices[index],\n",
        "                'date': dates[index],\n",
        "                'seller': sellers[index],\n",
        "                'image': images[index],\n",
        "            })\n",
        "    \n",
        "    def to_csv(self):\n",
        "        with open('rightmove.csv', 'w') as csv_file:\n",
        "            writer = csv.DictWriter(csv_file, fieldnames=self.results[0].keys())\n",
        "            writer.writeheader()\n",
        "            \n",
        "            for row in self.results:\n",
        "                writer.writerow(row)\n",
        "            \n",
        "            print('Stored results to \"rightmove.csv\"')\n",
        "            files.download('rightmove.csv')\n",
        "\n",
        "    \n",
        "    def run(self):\n",
        "        for page in range(0, 14):\n",
        "            index = page * 24\n",
        "            url = 'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E219&maxBedrooms=3&minBedrooms=3&index=' + str(index) + '&propertyTypes=&mustHave=&dontShow=&furnishTypes=&keywords='\n",
        "            \n",
        "            response = self.fetch(url)\n",
        "            self.parse(response.text)\n",
        "\n",
        "        self.to_csv()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    scraper = RightmoveScraper()\n",
        "    scraper.run()\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "rMWrsCZrfZ4C"
      }
    }
  ]
}